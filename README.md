# ðŸ¦™ Offline LLM with Streamlit + Ollama

This project lets you run an **offline AI assistant** using [Ollama](https://ollama.ai) and [LangChain](https://python.langchain.com).  
It has two modes:
- **Ollama Offline LLM** â€“ chat with a local model.
- **Document Summarizer** â€“ upload PDFs and ask AI questions.

---

## ðŸš€ Setup

1. Install [Ollama](https://ollama.ai/download) and pull a model (example):
   ```bash
   ollama pull deepseek-r1:1.5b
